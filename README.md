# tanh_normalization
Benchmarking a scaled tanh (DyT) against other normalization layers on CIFAR-10.

Paper: [Transformers without normalization](https://arxiv.org/pdf/2503.10622)

Code: [Github](https://jiachenzhu.github.io/DyT/)

### Feedback, Questions or Contributions

Any form of feedback is highly appreciated!
Whether it is about a spelling mistake, implementation bug, or suggestions for improvements/additions to the code. Please write issues here on Github, use the following link to submit feedback [julianhatzky.me/feedback](https://julian.hatzky.me/feedback), or feel free to reach out to me directly per mail.

If you find this helpful and would like to cite it, you can use the following bibtex:

```bibtex
@misc{hatzky2025dyt,
   title        = Tanh Function as Drop-In Replacement for Layernorm,
   author       = Julian Hatzky,
   year         = 2025,
   howpublished = julianhatzky.me/blog/2025/tanh/
}
```